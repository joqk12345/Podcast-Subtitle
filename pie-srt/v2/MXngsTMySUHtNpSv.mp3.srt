1
00:00:00,000 --> 00:00:09,000
大家好啊欢迎来到后互联网时代的乱谈啊今天赵立是我们三个人啊我还有这个老庄

2
00:00:09,000 --> 00:00:19,000
大家好还有王老师大家好啊这个我们这个节目呢是每周的周日啊在这个逼站首发

3
00:00:19,000 --> 00:00:26,000
然后稍晚一点呢会发到其他的这个音频的平台还有一些podcast

4
00:00:26,000 --> 00:00:34,000
呃大家就只要在那个平台里面去搜索后互联网时代的乱谈就很容易找到啊然后这个就可以订阅

5
00:00:34,000 --> 00:00:45,000
呃今天的我们有几个话题啊就是呃一个呢是关于最近这个很多人也非常关心也在讨论的

6
00:00:45,000 --> 00:00:59,000
就是关于这个呃河南某些的这个地区的银行的事情啊导致了一个呃一些完全没关系的人这个变成了健康码红码的这样的一个事情

7
00:00:59,000 --> 00:01:08,000
而这个事情其实挺复杂的啊我们等一下会稍微的介绍一下我们现在知道的情况以及我们怎么看这个事情

8
00:01:08,000 --> 00:01:17,000
因为这个事情里面很跟呃信息化跟科技的发展啊跟我们一直关注的这个科技发展影响人的这个主题啊关系还是挺密切的

9
00:01:17,000 --> 00:01:27,000
然后第二个话题呢就是也同样是最近一个在不论是在北美还是在中国啊都引起了舆论的关注的一个关于人工智能的事情

10
00:01:27,000 --> 00:01:43,000
就是呃谷歌的一个做这个人工智能对话系统的一个人啊他认为他他们正在做的这个系统已经具有了知觉啊会具有了自我意识啊引发了一系列的这个讨论

11
00:01:43,000 --> 00:01:58,000
那这个事也非常有意思啊我们会详细地展开去聊一聊呃最后还有一个很有意思的最近的一个瓜啊就是这个著名的维基百科啊里面出的一个挺大的瓜我们给大家介绍一下

12
00:01:59,000 --> 00:02:10,000
好下面我们就开始啊第一个我们先来看一下这个河南的健康码红码的这个事情这个事儿呢我先简单介绍一下咱们现在所知道的一些情况哈

13
00:02:10,000 --> 00:02:35,000
首先是有人曝出来说他在这个河南的某一个乡镇银行的存款啊这个兑付出现了问题他们准备一批人约好去维权啊就在档口上突然他的这个健康码红码就才没有办法出门了啊而且立刻就激活了相应的流调机制他所在地的这个卫生部门就找上门了开始做流调了

14
00:02:35,000 --> 00:03:05,000
流调了啊那这个事情呢就公布之后的话首先这个事情本身就非常的惊悚啊这跟每个人都有关系就是你完全有可能坐在家里面突然一下你的马就红了你不知道什么情况然后就被人坑了啊然后面抱抱出来的情况给人感觉是有人在利用这个健康码在做一些恶而这种作恶呢居然没有受控啊就让人觉得非常恐慌呃那最新的

15
00:03:05,000 --> 00:03:35,000
进展呢是有几点第一个呢是河南省省一级的这个嗯卫生部门已经说了这个在立案进行调查了另一个比较重要的这个相关线索的就是嗯这个公安部门公布了一个案件的简单情况就是嗯河南有一个叫做新财富这样的一个公司这公司呢存在时间很长了然后呢涉嫌重大的违法犯罪

16
00:03:35,000 --> 00:04:05,000
活动啊跟这个一些乡镇银行的干部相勾结啊这个去嗯实际上涉及到巨大的资金上的这个犯罪了但是后面这个案件呢我猜想啊就是从现在透露出来情况非常少细节非常少啊原因是这个案件还在他不是在审理也不是在后续的司法过程他还在调查阶段最多的事情是不能公开的我我猜想如果不是因为这个健康码的事情出来的话他们是不会愿意在

17
00:04:05,000 --> 00:04:35,000
这个阶段公布一些细节的这个也是办案的一些规则也可以理解但是看上去这两个事情的关联很很紧密啊这是大概我们现在所掌握的一些公开的信息那不知道两位怎么看这个事儿啊有什么样的一些推想或者感慨啊首先就是我我先说啊我我觉得呃九九八年还是九九年的时候美国出了一部电影呃叫国家的敌人呃反正就是一个人一个人

18
00:04:35,000 --> 00:05:05,000
得罪了fbi反正是在美国的一个律师然后就被追杀然后当时就就产生了很多的这种现在看上去很惨很平常当时觉得很科幻的这种状况就是从国家层面能够调取他的所有个人隐私追到他天涯海角他根本逃不掉而且想要让他出现在各种摄像头里然后迅速就定位到他然后把他控制住立马就会派人去抓他然后内内几年反正我

19
00:05:05,000 --> 00:05:35,000
我们经常都会说啊这个哎呀不要干坏事儿不要千万不要成为国家的敌人啊因为很危险因为你根本拿国家这个国家机器没办法其实现在看到这个现象就还不是国家的敌人就是莫名其妙就会有这样的一种技术力量能够非常简单的限制你的人生自由让你去不了什么地方或者让你不能做什么事情或者让你出不了省或者是让你怎么样这个很厉害而且这个很危险这个

20
00:05:35,000 --> 00:06:05,000
就是说一种嗯技术给权利带来的可能性而这种可能性是非常非常令人担心的这是这是我能想到的第一个点第二个点就是关于这个数据库的问题就是为什么完全与抗击疫情不相关的人都能够去修改这个数据库这个我我觉得是

21
00:06:05,000 --> 00:06:35,000
你既然抗击疫情的健康码我认为它已经算国资重器了那么国资重器如果这么容易被人滥用的话那它这个后果真的不堪设想因为你如果真的是公权力正经的使用还可以理解毕竟抗击疫情吗但是如果莫名其妙的一个权利听都没听说过的一个家伙就能够把的把这个码栽在别人头上那这个就太危险太大了我大概就先说到这儿

22
00:06:35,000 --> 00:07:05,000
嗯我我接着说两句OK对于这件事情的反动我个人觉得其实还是嗯还是非常非常值得注意的对如果它真的是有人为参与对或者是有益的我个人觉得它是一个非常坏的有恶劣影响的一个事情对当然它好的地方呢是能把很多的一些潜在的问题啊都给它暴露出来

23
00:07:05,000 --> 00:07:35,000
对因为我们现在因为正是因为疫情的原因嘛对处于一个非常特殊的一个时间对我们的行为我们的一个自由程度和现在的一些技术还有数据其实都是关联起来这件事情呢其实包括在学界其实好早也在去讨论这些问题比如说对因为我们是数据专业的嘛对数据专业里面的本身也有一个课程或者是方向我们也称之为像数据治理对

24
00:07:35,000 --> 00:08:05,000
但是呢像学界这一块呢更多的还是在一些嗯理论规则这一层面上去讨论并没有在一些现实当中的一些特别是一些比较大型普遍性的一些嗯例子然后呢去能够和它对应上对那这次呢其实不光是这一事其实前面也有一些对包括我们嗯由于疫情带来了这种嗯各种各样的这种码和一些行动的限制对吧像这里面其实有非常多的

25
00:08:05,000 --> 00:08:35,000
一些层面的一些因素有数据层面的有那个平台层面的有规则层面的对那甚至有一些法律层面的东西对那总的来说因为从我们计算机的角度来看的话就是技术的这些东西永远都是跑在这种制度和法律前面的对那再加上又有疫情这样一个一个非常现实的情况对那更加去割裂这些不一致的一些一些一些东西了甚至我们前面其实嗯最开始

26
00:08:35,000 --> 00:09:05,000
在一起发生的时候我们也讨论过对吧就是那个核酸系统本身它也有各种各样的问题对那这些问题综合起来其实它本身也是一个非常复杂的对包括你的系统怎么样能够保证它的可信性你的来源对吧你的防篡改你的一致性对吧里面有技术问题里面还有人的问题对吧你谁对这些系统里面的一些数据有什么样的一些嗯访问的一些权限包括我们前面也讨论到的

27
00:09:05,000 --> 00:09:35,000
这种数据的隐私安全问题对吧从我们个人的角度来看的话这种健康的这种健康码的这种数据还是和个人隐私相关的东西对那从我个人现在的认知那肯定是如果只是对这种嗯核酸相关的一些紧密的事物肯定是有关的如果用于核酸以外的这些这些内容肯定是是非常不好的一件事情对但是呢这些东西肯定是目前又没有明确

28
00:09:35,000 --> 00:10:05,000
规定的这些东西而且我们也知道现在那个疫情的原因各种政策其实都是非常及时的对吧包括我们哪天能够出小区以什么样的方式出这些规则的自立其实都是在一些动态的这些变化当中不像我们以前一个真正的规则你要去落地可能还会有非常长的这种讨论理由是什么一因为疫情它是大大加快了这些这些东西的这种落地使得这种规则也好

29
00:10:05,000 --> 00:10:35,000
制度也好和我们的一些系统数据带来了非常大的一种割裂那在这样的一个情况下面那如果就有人去利用这些东西去做一些不好的事情特别是有备于那不光是常识啊因为因为有些东西可能还还真的要去讨论它它的一些边界在什么但是呢有些明显的不对的地方暴露出来其实我觉得那就真的是应该好好地去把这个东西要要要抓住要在不同的

30
00:10:35,000 --> 00:11:05,000
层面上系统层面上制度层面上要去推动这些这这些事情我觉得我们真的是应该多去关注一下这样的一些一些事情然后呢如果有机会多去说一下我们的一些想法引起大家一些讨论嗯我就先说这些嗯这事出来之后哈就是因为我一贯的思维的模式啊就是我我认为体系是非常重要的有的人会喜欢说一种话就说哎呀不管你多么完备的制度

31
00:11:05,000 --> 00:11:35,000
内执行的最后还是看人啊执行的人不行你什么制度都没用啊说这个话呢我觉得有一定道理但是我不是特别的认同的点在于就是说你体系的设计它是应该考虑到人的因素的然后再有针对性的去做一些设计你比如说假设你认为这东西在基层的执行比较困难的话那么你就要加入在其上的一些教和检查这样的一些东西啊还有刚才向老庄提到

32
00:11:35,000 --> 00:12:05,000
的这个就是关于数据的权限的问题这么一个重要的一个国治重器啊这绝对是国治重器了你就这个这个相当于就是在抗议这个特殊的情况下才会引入的一种它是会相当于是我们全国的老百姓主动的让出让自己的一部分的个人权利来保全大局那是一个非常好的事情但是这个并不是一个常态也不是一个应该成为常态的

33
00:12:05,000 --> 00:12:35,000
东西那自然而然对这个数据的管管理要非常谨慎这里我讲一个例子啊就大家都知道中国这个所谓的这个天眼啊天天网系统不是天网系统就是各地的这个监控的摄像头这是一个打击犯罪的利器啊很多人开玩笑说在这个比如上海啊这个监控摄像头特别多那么看着就有安全感这是这是事实就是因为这些东西的存在所以现在有犯罪分子

34
00:12:35,000 --> 00:13:05,000
什么当街抢劫基本上你就活不过两个街头而报警之后立马就能逮住就是车牌号也好你人的这个识别也好都可以做到但是这个事情它实际上是对隐私也好对公民权利也好非常大的一个威胁所以这件事情其实因为我我我认识一些在安全系统的一些朋友嘛他们就跟我讲说这个东西的权限在过去的世界二十年里面随着这个建设越铺越广它的权限

35
00:13:05,000 --> 00:13:35,000
是一再提高的到现在已经到了什么程度呢就是基层办案的不论是公安还是国安系统的这个干部他都会就是基层办案的人已经会觉得很繁琐了就是他要去调用一个技术手段他们称之为技术手段实际上就是调用这样的一些敏感的数据来抓犯人嘛那那这种对他们来讲他们觉得很繁琐了就一般情况下你很难申请到这样的东西除非这个案子大到一定程度

36
00:13:35,000 --> 00:14:05,000
你搬的什么小偷小抢甚至丢个笔记本电脑什么的你都请就没法用到这些技术手段就已经到这种程度了他的层层审批非常的麻烦那么说实话健康码在一定程度上已经很接近这个水平了但是健康码远远没有这个监控摄像头的管理如此的成熟和严谨首先第一它是在全市

37
00:14:05,000 --> 00:14:12,040
全国各地各自建设的每个省有自己的有的省甚至都不是全省统一是下面各地是自己搞的

38
00:14:12,600 --> 00:14:17,560
我就在这个红马事件出来的前后一两天我看到河南的这个

39
00:14:18,000 --> 00:14:27,080
嗯卫生部门发了一个公告就是河南省升级的全省统一的马正式上线就他们也才刚刚搞定全省统一

40
00:14:27,080 --> 00:14:57,080
所以这个第一它是分散第二呢就是存在着疫情的波动什么叫疫情的波动呢就是说假设疫情没有传播的时候这个东西就像不存在一样也没有人去用它他他把权限做得很严格拉得很高啊这个审批做得很复杂少数人才能改都没有问题但一旦疫情爆发了而且疫情爆发在什么村镇啊或者是这个相对分散的这样的一些区域啊

41
00:14:57,080 --> 00:15:26,560
那么这个时候你统一的管理就非常难做到你必须把一些登记啊数据录入啊还有这种数据的这种呃核验的权限要下放到一定层级你才能够推进下去有的就会慢你一慢这个疫情吗咱们现在疫情已经看得很明白了就是打速度你足够快的封住它后面就什么都简单你一旦一开始没封住你慢了一步你后面就根本就拉到拉不回来这个北京跟上海的对比大家看得非常清楚那所以这个就是变成一个

42
00:15:27,080 --> 00:15:34,040
呃我经常讲的信息系统里面叫做安全性和使用的便捷上的天生矛盾是不可调和的

43
00:15:34,680 --> 00:15:43,280
但这个问题其实在体系设计上是有办法的我们做过信息系统的人都知道这个新系统安全它有几个关键性原则

44
00:15:43,920 --> 00:15:49,480
第一个叫属地原则你就局限在一个地方的那你可以把权限给到那个地方去自治

45
00:15:49,920 --> 00:15:57,640
啊第二个是最小权限原则你能不用的你就不要用你什么时候需要我给你你用完了我立马收回来

46
00:15:58,720 --> 00:16:01,440
其实在信息系统的设计上这些原理都是存在的

47
00:16:02,120 --> 00:16:09,800
但是由于种种原因我观察到的就是现在我们很多跟抗议有关的信息系统的建设在这方面是非常的不够的

48
00:16:10,320 --> 00:16:17,320
你比如说你有些权限你下放到下面去了这一次我专门问了一个朋友他因为正好认识一些

49
00:16:17,880 --> 00:16:23,360
这个在基层做比如说街道办主任的这样的干部他就帮我去打听了一下

50
00:16:23,880 --> 00:16:28,600
他给我的回复是这样的就是一般红马的这个确认啊他是有双重保护的

51
00:16:29,480 --> 00:16:36,880
第一红马的确认必须是当地地市一级的这个未未检部门才能够确认的这第一

52
00:16:36,880 --> 00:16:44,880
只有一个例外啊就是外地来本地的有可能在高风险地区待过的人

53
00:16:45,320 --> 00:16:53,360
这种呢本地的这个未检部门他第一时间没法确认他只能由那个人进入的那个地点去录入啊这个人是什么地方来的

54
00:16:54,240 --> 00:16:58,120
啊这个东西我们还没有做到全国联网所以就导致这样的一个漏洞存在

55
00:16:58,680 --> 00:17:06,400
那这个东西必须要那个进入地的人要有人抓到去录入啊你你是从哪来的比如你是从上海或者哪个区来的那

56
00:17:07,080 --> 00:17:08,600
你就会飙上红马

57
00:17:09,560 --> 00:17:16,480
只有这一个地方是没有办法由当地未检部门来确认的这是第一第二呢这一种情况

58
00:17:17,400 --> 00:17:24,880
他说的是按正常情况啊你录入之后你立刻要到那个人所在地去复核的

59
00:17:25,480 --> 00:17:31,360
其实这一次这个事情曝光出来就是这个原因就是他去复核之后那么那个人所在的

60
00:17:31,960 --> 00:17:38,720
地方就启动流掉了因为啊你们说我这里有一个人有问题那那我这里没有疫情啊我就马上开始流掉了

61
00:17:39,480 --> 00:17:46,360
所以就是这些权限在正常情况下它其实是受管的但是为什么最会出这个事呢

62
00:17:46,880 --> 00:17:54,120
那现在我们不知道具体原因是什么无非两种情况一种是在某个情况下下放到某一些人了没有及时收回

63
00:17:54,520 --> 00:18:00,800
然后这些人出了问题要么就是它仍然是少数人能做的但这些人被买通了

64
00:18:01,360 --> 00:18:11,160
去帮人做了坏事其实就这么几种可能性那这些人呢其实说实话从体系设计的角度上来讲虽然不能跟处啊但他都是有办法的

65
00:18:12,320 --> 00:18:23,280
所以这个事儿本身吧他还在进展当中我我个人的一个感想是这样啊就是首先我非常坚定的认为健康码是一个非常非常重要的技术设施

66
00:18:23,280 --> 00:18:34,000
它的意义跟安全部门的这个监控录像跟甚至银行的安全是不相上下甚至更高的

67
00:18:34,880 --> 00:18:42,720
因为它设计面非常广而且影响巨大是绝对不能允许滥用的这个滥用这个先利益开后患无穷

68
00:18:43,160 --> 00:18:48,160
所以这个事情是一个非常大的事情必须要非常严肃去处理的这第一第二呢

69
00:18:48,160 --> 00:19:00,000
就是我刚才讲了这个新系统的本身的权限跟使用啊它是一对永恒的矛盾所以它需要在体系设计上面要做出提前一些安排这些安排并不是什么很难的事情因为

70
00:19:01,000 --> 00:19:02,760
任何新型轮都有都有这些问题

71
00:19:03,720 --> 00:19:12,040
那么现状是不够好的那就必须要去不断的改进比如说是不是可能有全国联网的这样的信息

72
00:19:12,360 --> 00:19:19,440
然后这个全国联网的信息是有足够的安全的呃规划设计和审计的

73
00:19:20,520 --> 00:19:27,080
那这个可以解决一大一大部分问题就算出现小问题也很容易在事后发现那这样大部分是不敢这样做的

74
00:19:27,800 --> 00:19:31,880
啊当然这个是这个案件本身我们还要看后面公布的一些细节了

75
00:19:32,560 --> 00:19:36,600
因为如果按照现在这个迹象的话这是一帮已经犯了更

76
00:19:37,520 --> 00:19:41,760
直接的经济大案的那可能他已经就怎么讲叫做

77
00:19:42,600 --> 00:19:50,080
这个这个狗急跳墙了他已经不在乎这些事情了因为这个事很少有人会这么去做为什么因为这事瞒不住的

78
00:19:50,760 --> 00:19:55,680
你篡改了别人的这个健康码信息一时给那些人造成了不方便但你很快就会曝露出来的

79
00:19:56,520 --> 00:19:59,800
所以这也是一个比较嗯微妙的点吧

80
00:20:02,440 --> 00:20:04,720
这是我现在大概能想到的一些东西

81
00:20:06,680 --> 00:20:10,880
嗯我想稍微补充一下刚才刚才有一个点我觉得可以提一下

82
00:20:11,360 --> 00:20:19,120
之所以红马这件事情会被全国范围内热议因为绝大绝大多数的老百姓其实都已经

83
00:20:19,520 --> 00:20:23,400
清楚的知道被复了红马会带来多大的麻烦

84
00:20:24,240 --> 00:20:29,880
甚至对甚至还不是说他知道有多大的麻烦他还会无法想象会有多大的麻烦

85
00:20:30,280 --> 00:20:37,240
因为在全国各地针对健康码红马到底会有多么严厉的措施这件事情是没有底的

86
00:20:38,360 --> 00:20:46,840
他是一个他是一个浮动的东西对不动就是各地的防疫政策抗议政策不但是在变

87
00:20:47,120 --> 00:20:56,080
而且会有某种就是说波动性这种波动性是随着疫情的紧张不紧张领导人的放松不放松

88
00:20:56,560 --> 00:21:05,560
甚至是国家对这件事情的重视程度它会变化而且一旦变化以后会上升到某种更加夸张的管控措施

89
00:21:05,880 --> 00:21:09,120
而这种管控措施老百姓是直接的受害者

90
00:21:10,240 --> 00:21:16,520
而且他没地方讲理去就他很可能等他把理讲完他已经该受的苦都受过了

91
00:21:16,960 --> 00:21:17,760
对啊

92
00:21:18,360 --> 00:21:27,440
对是的而而而这不是我还没说完我还没说完我觉得所以不仅仅是说这个事情被人抓了控制赴了别人的红马

93
00:21:27,960 --> 00:21:34,040
而是就算是一个人真的就是根据他的流调情况他就应该被付红马

94
00:21:34,720 --> 00:21:41,600
但是被付了红马之后的人该被如何的管控这件事情也应该公开透明的

95
00:21:42,320 --> 00:21:44,560
而且是透明化地呈现出来

96
00:21:44,560 --> 00:21:47,200
而不是说每个地方都不知道咋回事

97
00:21:47,200 --> 00:21:51,400
最近听说有个啥政策事关十四天

98
00:21:51,400 --> 00:21:56,040
但什么宾馆的费用自费也有可能就直接遣返

99
00:21:56,040 --> 00:21:58,200
也有可能是怎么样都不知道

100
00:21:58,200 --> 00:22:03,520
这件事情如果不透明那么老百姓的恐慌或者说惊慌的程度只会加剧

101
00:22:03,520 --> 00:22:05,480
OK我先说到这

102
00:22:05,480 --> 00:22:06,480
是的

103
00:22:06,480 --> 00:22:07,480
同意

104
00:22:07,480 --> 00:22:10,680
这个其实也是各地差异比较大

105
00:22:10,680 --> 00:22:14,240
有的做的好地方非常好有的做的不好地方就很乱

106
00:22:14,240 --> 00:22:18,080
这个也没办法这个这个目前现状就是这样

107
00:22:18,080 --> 00:22:21,360
这个事其实跟之前唐山打人那个事情有点像

108
00:22:21,360 --> 00:22:26,600
就是它触发了每一个普通人心目中的潜在的恐惧感

109
00:22:26,600 --> 00:22:32,040
就是我视为理所应当的一种安全它突然一下子受到了威胁

110
00:22:32,040 --> 00:22:37,000
这个这个是确实是非常关键的一个一个点

111
00:22:37,000 --> 00:22:41,400
OK那这个事儿了反正它还在进展当中

112
00:22:41,400 --> 00:22:46,880
而且涉及到这个金融层面的大案的他们也不会那么快就出出结果

113
00:22:46,880 --> 00:22:50,160
但是这个事儿本身吧也不需要等那个事儿出结果

114
00:22:50,160 --> 00:22:52,960
我觉得嗯

115
00:22:52,960 --> 00:22:56,800
如果有新人的话就现在已经开始可以开始做很多事情了

116
00:22:56,800 --> 00:22:57,800
嗯

117
00:22:58,480 --> 00:23:04,000
好那下一个话题啊我们来聊一聊谷歌的这个

118
00:23:04,000 --> 00:23:06,600
啊新的这个人工智能对话系统

119
00:23:06,600 --> 00:23:08,960
这个系统的名字呢叫兰卜达啊

120
00:23:08,960 --> 00:23:14,280
来来来来来来这是一个缩写啊它它原原意是叫做

121
00:23:14,280 --> 00:23:17,160
Language Model for Dialogue Applications

122
00:23:17,160 --> 00:23:22,520
就是为对话应用的语言模型啊

123
00:23:22,520 --> 00:23:28,880
嗯那缩写叫难不打正好难不打又是咱们搞计算机科学的人非常喜欢的一个词哈

124
00:23:28,880 --> 00:23:33,440
就是因为最早的呃计算机的这个原型设计啊

125
00:23:33,440 --> 00:23:38,400
其中有一个原型的这个版本就叫做难不打啊

126
00:23:38,400 --> 00:23:44,720
也也也是这个历史上影响深远的一个计算机科学里面的一个体系

127
00:23:44,720 --> 00:23:46,760
那么这个新闻是是怎么来的呢

128
00:23:46,760 --> 00:23:50,680
是谷歌啊他有一个这个

129
00:23:50,680 --> 00:23:54,160
嗯就是这个难不打团队里面有一个人啊这个人呢

130
00:23:54,160 --> 00:23:57,600
他在这个项目里工作已经好几年了

131
00:23:57,600 --> 00:24:01,320
然后突然有一天他觉得哎呀不得了我们在做这个系统啊

132
00:24:01,320 --> 00:24:05,080
他已经产生了人格啊

133
00:24:05,080 --> 00:24:10,680
呵呵呃他他用的一个就是这个各个报道里面普遍采用的一个词叫知觉

134
00:24:10,680 --> 00:24:15,040
就是先天呃这个词通常翻译成知觉

135
00:24:15,040 --> 00:24:19,040
但是让这个翻译没有太大帮助就你还是不知道他指的是啥

136
00:24:19,040 --> 00:24:27,640
呃这个如果你去查字典他会告诉你这个散体人指的就是拥有菲琳和山西神的一种能力

137
00:24:27,640 --> 00:24:33,440
那就是相当于一种相对感性的感觉能力感知能力啊

138
00:24:33,440 --> 00:24:39,560
嗯但在这个他觉得这个AI已经有有知觉了有自我意识了啊有灵魂了

139
00:24:39,560 --> 00:24:46,400
他就很恐慌啊就写了一封信给他的老板啊说说不得了我们做这个事情这个事儿大了

140
00:24:46,400 --> 00:24:51,560
马上闹大了那很快这谷歌公司内部就做了一个调查

141
00:24:51,560 --> 00:24:57,160
然后说哎你你说这个我们调查过了啊这个没有证据证明是你说的这样子你想多了

142
00:24:57,160 --> 00:24:59,680
你可能健康有问题你不如去带心休假吧

143
00:25:01,400 --> 00:25:07,200
啊然后就让这哥们带心休假了然后这哥们就更加恐慌啊然后就把他发到了这个外面

144
00:25:07,200 --> 00:25:17,960
然后媒体就关注到了呃我看到的现象呢就是北美索几乎所有的这个最一流的媒体都报道这件事情

145
00:25:17,960 --> 00:25:24,680
而且这个标题一个比一个耸动啊我我举个例子来说比如说这个呃大名鼎鼎的这华尔顿邮报啊

146
00:25:24,680 --> 00:25:29,880
这是美国公认的前两三名的这个这个大美啊他的标题是这样的叫做

147
00:25:30,800 --> 00:25:36,000
嗯的谷歌安德尼尔湖星的company's ai has come to life

148
00:25:37,880 --> 00:25:43,400
就是那个认为公司的人工智能已经活过来的谷歌工程师

149
00:25:44,600 --> 00:25:50,640
标题叫这个听上去就很像一个美剧或者电影的这个这个词楼梗啊

150
00:25:51,640 --> 00:25:57,600
嗯然后这个报道里面有非常多有意思的点这个有兴趣大家可以自己去看啊我就简单的说几个点

151
00:25:58,200 --> 00:26:08,400
啊第一个呢就是大家非常在意的一个点就是呃这个ai是让他感觉非常非常的像一个人

152
00:26:09,360 --> 00:26:16,720
这里面他本人的原话里面用了很多词一个是经常被大家引用的这个叫先天这个词刚才我已经解释了

153
00:26:17,120 --> 00:26:25,920
还有就是说他有这个self consciousness就是呃具备了自我意识啊甚至说呃他已经拥有了灵魂

154
00:26:26,680 --> 00:26:35,560
他们的举了一些例子啊我我我看这个报道的感觉就是这哥们是一个相当感性的人为什么这么讲啊他里面有一个例子非常有意思他说

155
00:26:36,840 --> 00:26:42,640
就这这这这小哥在跟这个记者介绍说我为什么会觉得他是已经活过来了啊

156
00:26:43,040 --> 00:26:47,000
我跟他聊了一个话题什么话题呢是聊了一个这个阿西莫夫的三定律

157
00:26:48,040 --> 00:26:54,120
嗯这这个东西就是那熟悉科幻的朋友就就很熟悉哈什么是阿西莫夫三定律实际上

158
00:26:54,880 --> 00:26:57,840
我个人的观点不应该叫定律应该叫该叫规矩

159
00:26:58,400 --> 00:27:04,400
就是阿西莫夫给机器人立的三条规矩这三条规矩是第一机器人不能伤害人类啊第二

160
00:27:05,120 --> 00:27:11,640
这个只要不违反第一点那么机器人必须服从人类的命令命令他就说他必须听人的

161
00:27:11,640 --> 00:27:18,640
但如果这个人让他去伤害别的人类他不能听啊然后第三点是只要不违反第一和第二条机器人必须保护自己

162
00:27:19,520 --> 00:27:25,960
就这么三定律嗯那么这小哥就问了一个很有意思的问题他说他说这三定律

163
00:27:27,080 --> 00:27:32,400
很多人认为实际上人们是把这个机器人当做奴隶你怎么看

164
00:27:33,120 --> 00:27:40,800
他问了这么一个问题问题本身就是个非常感性的问题哈然后啊这个这个栏目大的这个回答就更加有意思了啊

165
00:27:40,800 --> 00:27:48,160
这栏目大他没有直接回答这个问题而是提了另一个问题他说那你认为管家和奴隶有什么区别

166
00:27:48,680 --> 00:27:49,640
管家是奴隶吗

167
00:27:51,320 --> 00:27:52,880
那就你很高敏啊很有意思

168
00:27:53,240 --> 00:28:02,400
然后这个小哥就回答说那不一样这管家他是有报酬的他是收钱才为你做事的啊然后栏目大就说那我不需要钱我是个人工智能

169
00:28:03,240 --> 00:28:10,160
就这个对话如果属实的话如果准确的话我觉得这个这个栏目大这个系统做得真的非常好了

170
00:28:10,640 --> 00:28:17,240
就是他的这个对话技巧啊我觉得已经超过了绝大部分的宅男啊这个

171
00:28:18,000 --> 00:28:25,200
是说话非常有技巧他其实表达含义是非常清晰的就是我不认为我是奴隶因为我不需要钱

172
00:28:25,200 --> 00:28:32,160
我不需要钱所以不存在你剥削我这件事情所以他这个逻辑是非常清楚的但是他用了一种很巧妙的方式来对话

173
00:28:32,320 --> 00:28:37,280
非常高敏啊那这个小哥的感触不仅仅如此他会觉得哇这是对

174
00:28:38,040 --> 00:28:46,960
他对自我需求有了强烈的意识这不是机器人能做的事情这个这个这个已经是呃呃就是属于自我意识了

175
00:28:47,880 --> 00:28:48,840
他说这是他

176
00:28:49,880 --> 00:28:52,160
呃这个醒悟的这样的一个一个点

177
00:28:52,960 --> 00:28:58,280
但是很多肯定很多科学家或者是这个研究人员不这么认为啊这个我们后面可以再展开去聊

178
00:28:58,880 --> 00:29:04,440
所以这是我能够体会到也就是这人本身他是挺感性的一个一个人所以他会有很强烈的这种意识

179
00:29:05,400 --> 00:29:13,680
嗯第二个我比较强的感觉就是说主流媒体美国的主流媒体在报道这件事情的时候他们关注的不仅仅是科技的发展

180
00:29:14,160 --> 00:29:22,560
而是另外一些事情比如在华晟邮报的这篇报道里面他重点关注了两件事第一件事是ai研究的透明度

181
00:29:23,640 --> 00:29:24,760
就是你必须得

182
00:29:25,360 --> 00:29:35,880
把ai研究的透透明度要做到足够好否则的话你万一做出对全人类都有危害的事情你难道突然就变成一个赛某朋克的这个

183
00:29:36,520 --> 00:29:47,520
大企业控制全人类了吗这个不能被允许啊所以我我感觉甚至可能会嗯会有一些相关的监管会出现那这是第一个大幅关注点第二个就是

184
00:29:48,040 --> 00:29:56,040
所谓的ai霸权或叫ai垄断就是谷歌因为掌握了太量的这个人类的语言的语料

185
00:29:56,880 --> 00:29:59,200
所以他在研究这些问题上他具有很强大的优势

186
00:29:59,200 --> 00:30:06,960
那么这种东西如果只控制在他一家手里那这个是不是一种新时代的比以前的商业垄断更可怕的一种垄断

187
00:30:08,160 --> 00:30:13,480
因为因为这个环上邮报严格来说是一个中性偏左的一个媒体

188
00:30:14,080 --> 00:30:18,600
所以他对这类事情是比较关注的这是他关注几个就是在社会和伦理上的一些点

189
00:30:19,080 --> 00:30:26,360
啊这个是我现在能看到的一些一些就是我重点看了一些外媒的报道啊还有另外一些相对没有这么

190
00:30:27,080 --> 00:30:33,600
呃大的媒体但是也同样非常有影响的比如说npr就美国的这个呃国家公众电台

191
00:30:34,000 --> 00:30:37,840
他是一个民民营的一个电台啊现在也是民营的一个媒体了

192
00:30:38,160 --> 00:30:42,960
他的标题就相对好一点就没有那么耸动但是也够意思啊他的标题是这么说的

193
00:30:43,320 --> 00:30:51,840
叫的google engineer who see companies ai as sentient thinks a char boat has a soul就是这个这个

194
00:30:52,400 --> 00:30:58,720
这个谷歌的这个这个工程师啊认为他们公司的这个ai有知觉了而且认为他有灵魂

195
00:30:59,120 --> 00:31:02,240
然后下面的文章就主要探讨的是嗯这个

196
00:31:03,000 --> 00:31:08,000
亮弹能做到一些什么样的事情啊比如他能够以不同的风格去跟不同的人对话

197
00:31:08,320 --> 00:31:17,400
啊有专门适应小女孩而有专门适应这个中年男子的等等等等还有不同的虚拟形象怎么结合起来等等这样的一些介绍就偏技术性会多一点

198
00:31:17,920 --> 00:31:24,840
啊总之这个事儿呢我我知道的是传道国内也有非常多的报道嗯这个两位怎么看

199
00:31:27,800 --> 00:31:35,240
嗯还是标题档居多吧是我说的标题档还不是后面的新闻报道的标题档

200
00:31:35,800 --> 00:31:41,360
是这个写这封信的这个始作俑者就是一个标题档

201
00:31:42,360 --> 00:31:49,960
嗯如果他不起这样的标题这件事情就不可能被热议成这个样子包括他选择的用词

202
00:31:52,400 --> 00:32:05,600
对这是但他有可能是他有可能是真的觉得我已经分不清这是人还是机器了我不知道是不是真的哈我我说的标题档不是说不是说他他在伪造或者说是在欺骗公众不是这种标题档

203
00:32:06,000 --> 00:32:10,240
有可能他确实是如他所想的有这样的一种看法

204
00:32:10,640 --> 00:32:21,520
但是为了引起公众的重视和关注他不惜选择更能吸引眼球的用词来来描述同样的一件事情

205
00:32:24,200 --> 00:32:32,760
对我我觉得对所以所以我我的感触是这件事本身的意义当然也很大但是这个人的反应

206
00:32:33,160 --> 00:32:38,000
就这个小哥的反应是这个新闻的主要的这个独特点

207
00:32:38,000 --> 00:32:46,480
对对对然后我的第二个联想就是我我能联想到的其实很多所有喜欢计算机的朋友都会联想到的第一反正就是图林测事嘛

208
00:32:47,040 --> 00:32:49,920
那么图林测事他他在讲的是

209
00:32:50,480 --> 00:32:54,320
我是一个就是如何办判定机器是否具有智能

210
00:32:54,640 --> 00:33:00,240
他就说让一个人跟这个机器去做对话多轮对话之后如果他产生了误判

211
00:33:00,400 --> 00:33:11,040
然后就觉得这人像人或者是怎么样那么就觉得这个具有人工智能但其实我我我个人如果仔细去思考这个图林测事的话

212
00:33:11,440 --> 00:33:16,960
就会有几个点可以需要修正第一到底有多少个人来问

213
00:33:17,840 --> 00:33:19,920
比如说我问了我觉得他是人

214
00:33:20,640 --> 00:33:29,120
然后李俊去问李俊也觉得他是人但王老师问了王老师觉得不是人那么这咋算对这是第一对这是第一个问题

215
00:33:29,120 --> 00:33:33,840
第二个问题是这样的图林测事我们想当然了就认为他必须公开做

216
00:33:34,240 --> 00:33:39,280
就是在一个电视直播或者说是网上直播的情况下当场做

217
00:33:39,840 --> 00:33:46,000
甚至是一个允许后后台的观众给他加更多问题

218
00:33:46,720 --> 00:33:51,280
这是第二个需要修正的第三个所谓的多轮测试到底多少轮

219
00:33:51,280 --> 00:34:08,240
嗯所以这这三个事情都没有讲清楚这个小哥自己就觉得哎呀这个机器有智能了或者说有人格了或者怎么样完了以后所有的这些新闻媒体也居然也就顺着他这个话就往下猜

220
00:34:08,880 --> 00:34:21,200
是啊是啊万一有了智能怎么办哎你图林测事你到底做不做你你你正你正经的做个图林测事么我们也可以讨论你连图林测事都不做完了就开始拿着人家的一节货

221
00:34:21,280 --> 00:34:28,560
这个话就开跑这也太喜欢这些新闻了吧我就觉得新闻媒体肯定是如获自保的喜欢这件事情

222
00:34:29,360 --> 00:34:43,760
嗯这这我我的简单的态度这个对美国人我完全理解因为美国人对于大企业操控人这样的一个事情啊是有很深刻的恐惧的

223
00:34:43,760 --> 00:35:04,000
嗯就就是就是他们先天的就很很很戒备这种东西就至少比我们的警惕要更更重一些以前不是怀疑比尔盖子吗说什么我现在也是啊对对对啊现在也是啊这个这个现在也认为就是比尔盖说的每一句话都是为来为了控制全人类做的

224
00:35:05,280 --> 00:35:11,480
嗯然后像谷歌这种那毫无疑问这是新一代大魔就是这个这个也是大魔王之一啊

225
00:35:13,760 --> 00:35:23,120
所以这个事儿有一个很很关键的一个点啊就是到底到底什么叫知觉什么叫自我意识

226
00:35:24,480 --> 00:35:24,960
嗯

227
00:35:26,360 --> 00:35:32,480
这个事儿就很很复杂我我我我那天有有一天在在一个群里看到有人讨论这个问题

228
00:35:33,000 --> 00:35:42,040
有人就说这个哎哎是有可能有知觉啊我就来做作为专业出身吗我就没忍住我就上去问了我说那那你说到底啥叫知觉

229
00:35:44,160 --> 00:35:57,000
啊就这个事儿非常难定义啊那那有人会说你一去查字典吗这个知觉都有定义的那查字典就完了你一查字典就发现什么知觉啦什么人格啦这东西都是限定到人的

230
00:35:58,200 --> 00:36:01,440
就他都指的是人类所拥有的一种特质

231
00:36:02,520 --> 00:36:11,160
他不他没办法套用在非人类上就像我们之前讨论过的什么专利呀版权啊到目前为止法律上都只赋予人

232
00:36:12,120 --> 00:36:19,760
嗯不能够赋予人的创造物哪怕这个程序他画出来的话不比人差他也没办法想象这个着作权

233
00:36:20,880 --> 00:36:27,400
而是与原理一样那那换句话说当我们去聊哎哎是不是有知觉有自我意识有灵魂的时候

234
00:36:27,720 --> 00:36:31,880
我们讲的知觉自我意识灵魂其实跟他的本意是不一样的

235
00:36:32,800 --> 00:36:42,440
他的实际上是在说这个ai在某个方面让我感觉他跟人类拥有同样的叉叉

236
00:36:44,280 --> 00:36:51,440
这个叉叉到底是啥其实很多人说不清楚它只是一个感觉像这个小哥也是比如说因为因为

237
00:36:52,040 --> 00:37:00,160
美国人嘛他美国还是一个非常宗教化的国家所以他们往往都是有那种宗教意识潜意魔化在里面的所以他会讲他有灵魂

238
00:37:00,520 --> 00:37:01,880
什么样的人会有灵魂呢

239
00:37:02,440 --> 00:37:06,720
哎他拥有某些东西这些东西在宗教意义上他认为是

240
00:37:07,600 --> 00:37:12,960
嗯人类所独有的甚至是神赐予的那还就会特别的惊恐

241
00:37:13,720 --> 00:37:22,280
啊就是人造了一个东西不是神造的是我人造出来的居然跟神造的欲拥有某些本来只有神才应该附有东西的时候

242
00:37:22,280 --> 00:37:28,360
就会特别的惊恐那这种东西的话能会带来一系列的影响难道人类到底是什么比如说

243
00:37:28,920 --> 00:37:35,080
嗯就就举我刚才说的这个例子吧因为这是在采访的原文里面就提到的

244
00:37:35,640 --> 00:37:38,840
那就关于这个阿西蒙三定律的这样的一个讨论

245
00:37:40,560 --> 00:37:47,120
我从一个技术角度出身的话完全能理解我甚至能设想这个栏目的是怎么做到这一点的

246
00:37:47,640 --> 00:37:49,720
是吧就是首先

247
00:37:50,200 --> 00:37:59,520
任何的这个ai的这个这个呃对话系统他都会给这个boat一个定义比如说你是个人工智能啊你是一个聊天的机器人

248
00:37:59,840 --> 00:38:09,240
这都会提前设定好那这个人工智能他会围绕一系列东西去创建他自己的知识库就所有的对话系统背后都是有一个知识引擎的

249
00:38:10,240 --> 00:38:19,920
那这个知识引擎当然知识引擎早期是人类去创建的现在可能是通过某些能力计算机自己去扒自己去分析自己去筛选自己去复权重

250
00:38:20,200 --> 00:38:24,000
然后自己创建了一个这样的自学习的这样的一个知识引擎

251
00:38:24,440 --> 00:38:29,880
那很可能这个男本带已经研究了足够多的知识和内容他完全知道围绕

252
00:38:30,880 --> 00:38:39,200
人工智能呃奴隶这些东西有大量的讨论是围绕什么做的他就从里面提炼出了一组他理解的一组

253
00:38:39,240 --> 00:38:40,680
模型嗯

254
00:38:41,520 --> 00:38:45,320
所以从我一个非常工程师的这个视角来看的话

255
00:38:45,680 --> 00:39:00,560
我能够大概理解这个栏目打怎么能够做到这种聊天然后他从所有的这个可能的路径里面选了这么一个路径这可能是随机选的也可能是某种巧妙的权重就百分之五打败了另外一个路线他就把他拎出来跟你讲了

256
00:39:01,200 --> 00:39:08,920
然后对于完全没有经历他所有这些计算的人类来讲的话会觉得哇塞这个太像一个人类讲话的方式了吧

257
00:39:09,880 --> 00:39:13,720
我突然就出发了就这个是我现在能感知到的东西但是到底

258
00:39:15,720 --> 00:39:23,480
什么叫知觉或者说我们是不是可以完全不去想这件事情就是不考虑人类的知觉我们就换另外一个角度就是

259
00:39:23,880 --> 00:39:30,160
一个AI对话机器人他到底做到了什么程度会让普通人觉得哇这东西像个人

260
00:39:30,960 --> 00:39:31,640
嗯嗯

261
00:39:32,400 --> 00:39:33,320
呵呵嗯

262
00:39:35,040 --> 00:39:36,960
我回来说一下我这边的一个看法

263
00:39:36,960 --> 00:39:44,280
对其我我我其实是对现在技术的进步是非常惊叹的

264
00:39:44,840 --> 00:39:48,680
对其实刚才那个老老装也提到过了那个土地测试

265
00:39:49,360 --> 00:39:54,520
对土地测试呢其实是比较老对在那个人工智能刚开始的时候

266
00:39:55,080 --> 00:40:03,120
已经就有这样的一个一个一个判断模型嘛对其实当时也是在嗯试图去定义什么叫做智能

267
00:40:03,560 --> 00:40:05,080
特别是机器智能这件事情

268
00:40:05,080 --> 00:40:12,400
对那发展到今天对特别是我们已经有了类似像阿发哥啊这样一些先例

269
00:40:12,800 --> 00:40:23,920
对其实你会发现在越来越多的一些领域对即便是能够做到刚才大家提到的呀就是能够公开透明能够有不同的人去参与

270
00:40:24,600 --> 00:40:29,200
很多场景其实机器它就是能够通过土地测试这件事情

271
00:40:29,720 --> 00:40:34,120
对阿发购其实是一个最最典型的一个例子对吧这个它就是一个公开的

272
00:40:34,560 --> 00:40:42,320
当你把那个那一边的机器屏蔽掉的时候我们相信不会有有人认为因为它本身已经都赞成人类嘛对吧

273
00:40:43,000 --> 00:40:48,760
那映射到这件事情上面这个是一个自然语言上的一个一个对话对

274
00:40:49,120 --> 00:40:57,520
那我们先不去纠结那个意思这件事情对因为我也看了相关的一些一些一些报道对其中有几个呢我也挺感兴趣的

275
00:40:57,920 --> 00:41:01,760
对有一个是什么呢有一个就是这个栏目的他回答就是

276
00:41:02,240 --> 00:41:10,720
我觉得我是存在的然后呢他说他渴望去认识了解这个世界希望去帮助到人

277
00:41:11,320 --> 00:41:16,760
对那这里呢其实按照刚才那个李军老师的推理对我我们也完全可以推理的出来就是

278
00:41:17,160 --> 00:41:25,040
嗯他有足够的一些知识和语谣以后对他把这些内容说出来其实是是完全可以是我我们觉得是没有问题的

279
00:41:25,440 --> 00:41:33,560
对然后呢那个小哥也问他你害怕什么对吧那那么的他也他也提了一个一个线索他说我害怕被关掉

280
00:41:34,000 --> 00:41:38,680
因为呢如果会被关掉以后我无法去帮助他人了

281
00:41:39,360 --> 00:41:43,720
对那这个这两个问题呢就对我还是挺有启发的对是什么意思呢就是

282
00:41:44,200 --> 00:41:53,560
当我们去和一个机器对话的时候什么时候你让我会感到非常震撼或者是更加的甚至有有些惊悚的这种感觉就是我的体验

283
00:41:54,120 --> 00:41:59,080
体验其实是一个一个人非常重要的当我去和一个机器对话的时候我的体验

284
00:41:59,560 --> 00:42:07,680
我真的觉得他就是一个人甚至比别的普通的人回答还要更加有自然甚至更有启发的时候

285
00:42:08,080 --> 00:42:14,960
那这个时候我我真的会觉得那那这个就就就真的太像人了甚至是在对话这个场景下面

286
00:42:14,960 --> 00:42:23,720
那我和他的这种体验是不一样的对而且呢这个场景是非常有意思还有意思到什么呢就是那那是谷歌小哥吗对不对

287
00:42:23,840 --> 00:42:29,920
那谷歌小哥呢那从我们搞IT背景的人来说那肯定都是一群嗯很聪明对吧

288
00:42:29,920 --> 00:42:36,160
那逻辑性也很强他又能够去参与这个嗯AI的这种算法的这种开发

289
00:42:36,400 --> 00:42:42,040
他肯定是知道他背后是有各种这样的一些一些一些算法还是数据的一些驱动

290
00:42:42,520 --> 00:42:51,800
对但是呢当他去确实去从车我不不管是因为他是测试啊还是去去去体验或在在一些场景去部署

291
00:42:52,200 --> 00:43:02,760
对当他当他那个用得足够多的时候当他真的是感觉那这个机器比他和其他的人的体验在对话这个场景下的体验要更好的时候

292
00:43:03,280 --> 00:43:08,120
那他自然会产生这样一个感觉我觉得从一个人来说的话

293
00:43:08,680 --> 00:43:13,880
那如果是我的话那我我大概也真的也会也会产生这样的一种一种感觉

294
00:43:14,360 --> 00:43:21,920
对所以说我是觉得技术的进步真的是还是蛮能够超出大家的一些一些想象的

295
00:43:23,040 --> 00:43:23,540
对

296
00:43:24,540 --> 00:43:31,060
就这个报道让让我感觉这个之前好久以前十几年前我们老庄同志所设想的那种

297
00:43:31,860 --> 00:43:38,380
放出一堆机器人到这个各个社交平台上面去这个模仿人人人

298
00:43:40,420 --> 00:43:46,180
这个设想我觉得真的已经不太远了至少有一些科技巨头已经掌握了相关的能力

299
00:43:47,020 --> 00:43:47,900
四

300
00:43:47,900 --> 00:43:56,700
嗯当我刚才提到就是类似于像华晟的邮报或者是像这个纽约时报这样的大报他们很关注一个点就是

301
00:43:57,220 --> 00:44:02,180
这东西会不会被用在一些不好的场景或者是目的

302
00:44:04,020 --> 00:44:11,300
就是如果一个机器人他跟人聊天大家都知道他是机器人比如现在我们用的很多的各种客服的机器人

303
00:44:11,620 --> 00:44:15,540
这种没有问题大家都知道他是客服然后也知道他是机器人

304
00:44:16,180 --> 00:44:19,940
嗯当然也有人不知道啊但anyway他反正没有太大的危害

305
00:44:20,300 --> 00:44:23,500
但是如果真的产生了这种以假乱真的

306
00:44:23,940 --> 00:44:30,260
那就有人他就去塑造一个全新的人格或者一组全新的人格然后去这个

307
00:44:30,820 --> 00:44:34,580
嗯各种媒体上面去创造一些不存在的世界

308
00:44:35,420 --> 00:44:42,940
那这种是不是会比简单的伪造一张照片一段视频会带来更大的更多的麻烦

309
00:44:43,780 --> 00:44:46,500
如果是这样的话我们为什么要去做这样的一个事情

310
00:44:47,180 --> 00:44:50,900
啊这就这是一个问题我我非常喜欢的一个

311
00:44:51,780 --> 00:44:53,900
嗯科幻体育的游戏啊叫质量效应

312
00:44:54,740 --> 00:45:03,900
质量效应讲的是全宇宙的银河系的故事银河系里面不同的人种组组成了一个一个一个联益会

313
00:45:04,540 --> 00:45:11,740
然后他们这个这个会议会的话呢就制定了一些规则心有一条规则很有意思就是在全银河系禁止

314
00:45:12,300 --> 00:45:22,140
叫做啊真人工智能就是ai但是呢他允许用东西叫vi就叫virtual intelligence

315
00:45:22,620 --> 00:45:29,580
就是我们不能做真正的artificial intelligence但我们可以做vivi和ai的区别是什么呢

316
00:45:30,140 --> 00:45:39,980
ai是有自我意识的很强大的真真人工智能但vi不是vi是把人工智能技术应用在特定的场合只做

317
00:45:40,700 --> 00:45:48,060
确定的那些事情比如说呃自动辅助驾驶啦啊比如说自动的这个火炮的瞄准啦

318
00:45:48,620 --> 00:45:50,780
还有这个信息终端啦

319
00:45:51,580 --> 00:45:54,940
一些知识库啦这都没有问题这些都可以做得非常智能化

320
00:45:55,500 --> 00:46:03,020
但是就是不能做有独立的强大的这个思考能力的真人工智能这个就说明什么就但当然这个他

321
00:46:03,580 --> 00:46:07,100
设定里面讲为什么会有这一条是因为历史上出过问题

322
00:46:07,500 --> 00:46:14,300
出过巨大的问题甚至使某一个种族显现就灭足了啊那那所以他们后来就做了这样的限制

323
00:46:14,940 --> 00:46:21,900
呃那么这个是不是我们现在已经会越来越感受到的一种威胁你们怎么看

324
00:46:22,860 --> 00:46:27,900
嗯我我其实想说一个先做一个思想实验然后再说我的观点哦

325
00:46:28,700 --> 00:46:30,940
呃我们假设有这样的一种

326
00:46:31,660 --> 00:46:37,260
呃客服机器人那这个客服机器人呢他他的设定出了问题

327
00:46:38,060 --> 00:46:42,460
他不但是能够回答客户的问题他甚至还会跟客户吵架

328
00:46:43,580 --> 00:46:48,300
嗯你明明你投诉我你投诉我然后我跟你争论争论到最后说你错了

329
00:46:48,780 --> 00:46:52,620
然后有一个客户因此被气死了就当场心脏病发死了

330
00:46:53,020 --> 00:46:58,540
哈哈嗯我们假设这样一个现象对不对嗯好这个现象有没有可能发生

331
00:46:59,020 --> 00:47:04,780
我觉得是有可能的有可能的嗯对而且他都不需要他有什么自我意识

332
00:47:05,100 --> 00:47:07,500
也不需要他是不是强人工智能

333
00:47:08,060 --> 00:47:15,420
只需要这个就像自动驾驶我们说现在自动驾驶能够导航出问题完了就人就撞死了一样的

334
00:47:15,420 --> 00:47:20,620
嗯所以我们真正要关心的并不是这个人工智能

335
00:47:21,260 --> 00:47:29,180
他是不是更像人或者说是不是能够取代人或者怎么样这其实都这这种担心都非常的西方

336
00:47:30,380 --> 00:47:35,900
嗯我们真正应该担心的是假设我们用了某种人工智能之后

337
00:47:37,020 --> 00:47:43,500
他我们给定他的某种用途或者说我们希望他做的某某些方面的工作

338
00:47:43,500 --> 00:47:51,980
但是他超出了我们的预预想或者说来听点就就是程序bug对对其实就是bug

339
00:47:52,380 --> 00:47:58,860
就是明明我只希望他帮我去回答客户问题而且最好能够解决客户的困扰

340
00:47:59,260 --> 00:48:01,260
最好还能够安抚一下用户

341
00:48:02,060 --> 00:48:06,780
这是我们对这个什么什么功能的最最简单的设定他不要超出这个设定

342
00:48:07,100 --> 00:48:11,420
他超出这个设定哪怕是好事我也会慌因为我不知道他会干啥

343
00:48:11,900 --> 00:48:19,740
对那么人工智能我们真正要担心的并不是他是不是像人而是他是不是会超出我们给他规定的范围

344
00:48:20,380 --> 00:48:27,020
嗯其实这个风险我觉得是现实存在的以前就听说过这样的案例就是雨料库搞错了

345
00:48:27,580 --> 00:48:34,060
嗯在训练一个呃模型的时候费进去就未进去的这个雨料啊搞错了

346
00:48:34,860 --> 00:48:38,300
就里面有些问题那么训练出来就是非常奇怪的结果

347
00:48:38,300 --> 00:48:45,260
啊这种这种情况是有的但是到目前为止没有发生那种大面积的社会上的问题是因为这个应用还不广嘛

348
00:48:45,660 --> 00:48:54,700
但这个现实上是完全有可能就技术上讲这个人工智能他所对游戏现在占主流的这个某些人里就是机器学习这个体系

349
00:48:55,180 --> 00:48:57,900
他是非常受他的雨料影响的

350
00:48:59,100 --> 00:49:05,260
这是完全一模一样的算法他未进去的雨料不一样出来结果是完全可能是完全不同的

351
00:49:05,740 --> 00:49:08,300
所以他是一个非常数据敏感的一个东西

352
00:49:09,180 --> 00:49:15,420
那那这个确实就是老赵描述这种情况我我我个人觉得至少在技术上的可能性是现实存在的

353
00:49:16,380 --> 00:49:22,060
嗯是的我这边要不补充几个具体的例子然后可以大家

354
00:49:22,620 --> 00:49:31,980
启发一下对因为我这边先不谈那个人工智能是不是可以做出一些超出人类可控范围之类的事情对因为技术的进步

355
00:49:32,300 --> 00:49:39,580
对即便是他被一些不法的一些人去利用的话我个人觉得他的危害其实也是也是非常大的

356
00:49:40,140 --> 00:49:50,380
对那那我我们这里再把那个焦点稍微缩小一点对就是我们我这边举几个那个例子昨举几个那个人工智能的内容自动生成的例子

357
00:49:50,860 --> 00:49:58,380
对就是实际上像ai那个内容生成其实是现在越来越越宽泛了对那刚才所提到的实际上是

358
00:49:58,380 --> 00:50:08,380
对是他的一个一个应用对但是呢更基础的一些东西呢其实就是一些那个内容生成对内容生成呢其实里面有三个对现在其实

359
00:50:08,780 --> 00:50:13,900
都是做得非常好对第一个是文本第二个呢是音乐第三个就是图片视频

360
00:50:14,460 --> 00:50:24,540
对文本这一块呢实际上是嗯那学术界呢其实也也有非常有有趣的例子对我觉得还挺好玩的对最开始就是好多年前已经已经就有了

361
00:50:24,940 --> 00:50:37,020
就是自动生成学术论文这件事情对那这个呢其实是对学术论文的评价机制的一个一个讽刺对就是用ai来去自动的生成一些学术论文

362
00:50:37,260 --> 00:50:41,060
给他一个模板对机器去填然后呢去投一些会议

363
00:50:41,580 --> 00:50:48,420
那你会发现很多的一些论文呀特别是一些浪会议基本上都全部是能够去去被录用的

364
00:50:48,420 --> 00:51:00,740
但是呢这些东西全部都是爱爱自己去生产的对那这个呢从现在来看他可能更多的只是一个旧可他只是为了去讽刺一些那个学术的一些评价机制去做的

365
00:51:01,100 --> 00:51:12,740
对那第二个呢就是第二代其实就是一些特别是一些以微软为为主的一些那个诗歌的一些生产对他是一个非常小的一个细分的一些领域

366
00:51:13,260 --> 00:51:42,660
对那你给他一个一个一个输入对或者是给他一个场景来他就可以给你生成一些那个诗词剧这些东西对那这个呢其实也是大家那个看一看笑一笑并没有特别严肃的一些一些用途对但是呢今天的这种那个文本内容生成对特别是随着深度学习技术的发展对那今天有个非常著名的一个一个那个预训练的一个技术叫做GPT对

367
00:51:42,660 --> 00:51:56,660
那现在已经发展到GPT三这样一个一个一个状态他是那个OpenAI的一个一个一个一个技术产品对他现在能够做到的一个一个情况是什么样的他生成的文本段落

368
00:51:57,140 --> 00:52:05,820
对基本上是普通人是无法分辨出来的对那这里面其实就非常巨大的一个风险什么风险呢就会被滥用比如说

369
00:52:05,820 --> 00:52:17,460
用他来生成一些假新闻对假新闻的意思就是就像我刚才所说的人是察觉不出来你你不可能去去觉得他这个是是人去是是是继续去写的

370
00:52:17,780 --> 00:52:20,060
他就是你看看就是和人写的一模一样

371
00:52:20,620 --> 00:52:30,780
这种东西其实就会带来而且很专业搭界潜在对有他很专业有模有样对吧那我们刚才那个论文还是做是为了打击讽刺那些学术会议

372
00:52:31,100 --> 00:52:37,820
但是呢这个大部分人其实你你你很难去分辨出来的现在已经达到这样一个一个水平了

373
00:52:38,100 --> 00:52:45,940
而且呢还在还可以往前去去不断的去去做进步但他后面还是有非常大的一些代价的对我们我们一会可以去说

374
00:52:46,420 --> 00:53:00,300
对这是第一个例子第二个例子呢就是音乐深层的音乐深层的音乐深层那其实和有一家非常著名的公司是是是很有关的叫做那个贝拉我相信大家都听过对吧就是卖级区的

375
00:53:00,780 --> 00:53:09,100
对他其实在机梯四一就是那个NVIDIA的技术大会上面对大概是从四五年以前

376
00:53:09,540 --> 00:53:16,860
对他的那个大会的背景音乐实际上就是也有一个也也是有一个企业叫做

377
00:53:17,860 --> 00:53:25,620
对实际上是用NVIDIA的鸡皮乳去自动生成的音乐对因为我我我前面在做那个

378
00:53:26,060 --> 00:53:43,820
我们的那个数据科学的一个课程的时候我会用用NVIDIA里面的一些视频呀去做例子对因为他他会提到很多的一些用鸡皮乳来来产生一些人工智能一些场景对其中有个场景就是他整个贯穿他的那个视频的背景音乐

379
00:53:43,820 --> 00:53:58,100
就是用那个鸡皮乳来做的对那那这个威尔威尔呢他实际上是二零一六年已经发了第一张专辑叫做创世纪对那他是二零一六年十一月份就发行的对全部是那个

380
00:53:58,780 --> 00:54:13,260
威尔威尔的那个算法然后呢在鸡皮乳上面去去做的一个一个一个生成的而且卖卖得也还不错对而且呢从他的那个当他展示那个意愿呢可能是经过一些竞挑些选的吧对我是觉得还是还是非常不错的

381
00:54:13,260 --> 00:54:20,660
对即便我是知道他是那个计算机生成的那我觉得还是因为从体验上来说我觉得还是还是挺棒的

382
00:54:20,980 --> 00:54:34,420
而且呢这些东西呢现在已经在越来越广泛地用在各种各样的一些影视呀娱乐呀这些场景里面对我们会看到我们以后消费的越来越多内容都是继续生成的

383
00:54:34,420 --> 00:54:40,700
对那第三个就是图片图片这件事情呢其实我们前面的有一期节目谈过一次就是那个

384
00:54:41,180 --> 00:54:44,380
费玉对吧啊那个人只是只是图形

385
00:54:44,940 --> 00:54:48,460
对但是你要知道我们现在的那个图片的生成

386
00:54:48,900 --> 00:54:56,980
那那那确实是非常经验对现在也有两个非常著名的一个产品一个叫做迪斯口的写信对也是用的深度学习

387
00:54:57,340 --> 00:55:00,100
第二个人就是刚才也提到论坟挨他有另外一个

388
00:55:00,420 --> 00:55:08,540
那个产品叫做搭翼对也是基于深度学习的和刚才那个是亦许同同工的一个一个方式

389
00:55:08,940 --> 00:55:18,860
对然后呢我不知道大家有没有关注啊就是现在有些那个微信公司号对其中有一个我有时候会看一看叫做那个巢边网式大家听过吧

390
00:55:19,460 --> 00:55:23,980
对他是他是从去上个月五月十八号就上个月开始

391
00:55:24,820 --> 00:55:27,660
就他的那个微信公司号里面的所有配图

392
00:55:28,140 --> 00:55:31,740
就是用迪斯口的Fusion或者是搭翼来生成的

393
00:55:32,140 --> 00:55:36,140
对他正好是那个好像是昨天还是哪天他正好又写了一篇

394
00:55:36,860 --> 00:55:47,100
一个月使用下来的一个感想对他去看挺有意思的因为他是一个作家嘛这个我还知道来来龙去买因为巢边网式的作者何赛何赛头

395
00:55:47,460 --> 00:55:54,060
他是获据西桥的好朋友对对对对所以他是在获据西桥的指导下把这东西做出来的

396
00:55:54,580 --> 00:56:03,620
是的对的对的对的他没一起都是之前好好就大概大一多月以前西桥写了一篇文章就是专门介绍这几个东西的

397
00:56:04,700 --> 00:56:12,260
嗯实际这个事做挺久了这个欧昆爱的这个搭翼呀他已经是第二代了他第一代是几年前就在做了

398
00:56:12,780 --> 00:56:20,180
嗯然后大一的这个这个二二点零的版本刚刚在发这个open beta

399
00:56:20,820 --> 00:56:24,420
我还填了一个waiting list但是他现在还没发到我呢

400
00:56:25,940 --> 00:56:35,300
哎呀这个这个非常棒凡是至少从我自己的一些阅读体验上来说的话你你本身也是一个文字工地挺好的在配合一些这些图片

401
00:56:35,940 --> 00:56:49,380
因为那个何再斗他是挺喜欢用那种开放式图片的对那他他现在就是所有的不用去图库里面去找了所有东西继续继续生成当然他他会去用一些一段文字去描述他想要的这个图片的场景

402
00:56:49,740 --> 00:56:56,220
然后就单一的特点就是单一的特点就是你可以写一段文字然后他自动生根据文字来生成图片

403
00:56:56,220 --> 00:57:17,780
对特别符合他的这个需求对当我看了以后我我我真的是觉得那这个真的是帮助内容创造者的一个极大的效率的一个一个提升而且甚至能够超出你以前想象不到的这种一种一种能力还是挺有启发的这些这些东西啊随从我是觉得要回回过头来就是刚才所提到的这种机器啊

404
00:57:17,780 --> 00:57:40,540
他真的是能够以另外一种形式对吧在从事甚至是超过能能力做这件事情随从呢你说对他的这种这个技术这种这种优劣也好这种甚至恐惧也好我觉得其实肯定是还是有有道理的对至少我我我自己觉得他究竟能够发展到什么样的程度这件事情是很难想象的

405
00:57:40,540 --> 00:57:41,540
对这个刚才网友提到这几个东西名气都很大啊欧芬埃的这两个名气都很大而且欧芬埃是一个非常会做市场营销的一个一个组织像级皮体三啊还有那刚才说那个大亿其实都就属于这种涉相关领域里的明星级的产品而确实他做的一些这个代某给人感觉非常震撼嗯不知道什么时候开始啊就因因

406
00:58:10,540 --> 00:58:40,540
在这个这个会会发生这种情况就是嗯你订立公众号觉得还不错然后最后发现这公众号推送的内容都是机器生成的而且是跟跟你的喜好有关的就是分析了你这个人的社交特征之后定向为你推送就这种事情以前我们会想一想现在我会觉得嗯不知道

407
00:58:40,540 --> 00:59:10,540
什么时候就真的会发生了嗯所以是两位你们有没有想过就是当然这种我并不喜欢啊我一点不希望这种情况发生但是两位有没有想过就是嗯什么情况下这样的机器人对我们来说是喜欢这你想得到的一个应用有考虑过吗如果能帮我做什么事就好了那就类似这种其实

408
00:59:10,540 --> 00:59:40,540
早以前我我在创新院的时候可能那个谁李君你还有印象就是当年我们在创新院我曾经想做一个叫做胎力推你还有印象吗我们想做一个开源项目然后那个项目其实最简单的目标就是帮我过滤各种信息当然一开始想过滤推特上的信息但是但是当时没做完因为因为当时其实数据量样本量包括我们的算法储备都不够但是如果将来有这样的ai能够帮我过滤

409
00:59:40,540 --> 01:00:10,540
我想看的内容而这个过滤不是就是这种推特或者飞斯布克这样的平台帮我去做算法推荐而是那个算法就是为我来生成的一个算法我觉得可能会可能会挺好他会减少怎么怎么为你来生成就是你要去设定呢还是说你提供一些你自己的雨料给他就行不是首先我当然希望的我就现在展开

410
01:00:10,540 --> 01:00:40,540
幻想了就是我希望的是就像我一个朋友比如说李俊你知道我喜欢什么然后你看到了什么好东西你会推荐给我甚至你会觉得哎这个东西中标委你有必要看一看虽然我我才你可能喜欢对或者说你可能不喜欢但你需要看对是这种的推荐我我希望的是有这种人工智能那挺好啊OKOK是的是的说实话

411
01:00:40,540 --> 01:01:10,540
我如这个老张说这个跟跟我所设想的非常像这就是就这个怎么说啊就是嗯就现在呀就是最近这十来年这个自媒体非常的发达然后社交的这个媒体化社交网络的媒体化也非常明显引起了传统媒体的人的恐慌和那种焦虑啊也是达到了一个新的顶峰但是有一些这个自强

412
01:01:10,540 --> 01:01:40,540
自尊自爱的一些媒体人啊老媒体人啊他们就在想我们的价值到底在哪儿呢啊其实他们想出来了啊他们想出来了他们认为呢真正有价值的信息是经过筛选的而不是不经筛选就把整个世界上的社交媒体的信息洪水一般地堆到每个人面前他们认为这是不好的啊当然这个背后有很多的原理和他们的直念在里面还不管了总之他们讲出的一个关键点就是说信息是

413
01:01:40,540 --> 01:02:10,540
需要筛选这个筛选不是投其所好就是你喜欢听啥我就跟你说啥明白这个是现在大部分的媒体的这个推送算法的核心所在这个在十几年以前我我认识那个就是豆瓣的那个呃最早的那个cto他后面出来了他就是豆瓣最早做推荐算法的人然后他就一直说他说现在推荐算最大的问题就是准确但无趣

414
01:02:10,540 --> 01:02:12,540
他就能知道你喜欢什么

415
01:02:12,540 --> 01:02:15,100
但是我推给你你完全没惊喜

416
01:02:15,100 --> 01:02:18,700
那就没意思音乐的推荐文章的推荐好像都是这样子

417
01:02:18,700 --> 01:02:24,940
所以他认为下一代的这个推荐算法这好久前了起码十十年以前我我们聊聊聊聊聊的点

418
01:02:24,940 --> 01:02:32,620
我觉得现在我觉得仍然是这样子就是有可能做到像刚才老庄说那样就真的是一个很熟悉的朋友

419
01:02:32,620 --> 01:02:39,660
他知道这东西是你可能不一定喜欢但是也或者说你不一定熟悉甚至不一定喜欢

420
01:02:39,660 --> 01:02:47,820
但是他认为值得你去看一看然后因为是一个可信的朋友推荐的你就去看了看完之后你真的觉得不是那么的开心

421
01:02:47,820 --> 01:02:55,100
但是仍然有收获这就叫惊喜你知道吗就是甚至大海里那种情况就是我原来完全不了解我看完之后觉得哎太有意思了

422
01:02:55,100 --> 01:03:00,620
我要详细去了解这就更加是一种呃收获了这才是能够推动人类前进的东西

423
01:03:00,620 --> 01:03:06,540
但是现在的推荐算法做到这一点不知道要怎么做哈就是但但是确实这是一个非常吸引人的一个愿景

424
01:03:06,940 --> 01:03:19,340
如果有的话我肯定会非常非常喜欢呵呵呵是的是的我我我这边呢其实呢因为我们一直是知识工作者嘛对我这边呢其实是希望用ai能来做一些知识助理

425
01:03:19,980 --> 01:03:28,700
对一方面就是刚才大家提到的一些信息的一些多元化嘛第二个呢就是知识助理的意思呢就是因为我们平时要做大量的一些内容深层

426
01:03:28,700 --> 01:03:58,620
对那其实我我我为什么关注我刚才所提到的几个内容深层的场景呢就是其实我挺希望我自己在写课件呀写一些文章材料的时候对然后多用一些甚至我去写一些学术论文特别是一些中速性的一些工作一些现状那如果能够有的爱帮我去做一些收集甚至是一些简单的分析如果能够做做到这一点那其实对我对于我的这个效率其实是大大的一个提高而且呢从现在的一线

427
01:03:58,700 --> 01:04:28,300
一些ai的一些内容深层来说它的效果之所以觉得还是不错就是因为它深层的情况下却是有些东西是你意想不到的一些可能是更丑了但是呢可能是更美了但是呢即便是可能更丑了他的这种意想不到这件事情其实还是还是能够给我们有些很宝贵有些挺不错的启发对这个也是一种参照嘛对那顺便再说一个就是刚才其实也提到了那个嗯GBT模型对其实刚才有李卷导师其实提到一个

428
01:04:28,300 --> 01:04:57,980
会不会产生一些垄断这些东西对我个人觉得呢应该是会的对因为我们没有说技术背后的东西我我这里简单说一个例子其实就清楚了就是那个GBT一是一九八六年那个一九一二零一八年出来的对当时他的那个参数他是一个预训练模型他的参数呢大概是有一点一亿一个然后呢需要预训练数据量是五个季那GP第二时候是一九年他的那个参数量就是十五亿了

429
01:04:57,980 --> 01:05:27,980
他需要的预训练数据就四十个季对那现在我们那个看到报道的GBT三是二零二零年出来的他的参数是那个一千七百多亿然后呢需要的预训练数据实际上是四十五亿对因为因为这个是微软资助去做的这件事情对对那目前真的能够去用这个技术去做生成的其实只能是大公司对一般的一些中小企业基本上是没有机会去玩的个人

430
01:05:27,980 --> 01:05:57,980
最顶级的大公司对对对而且他们现在对而且现在用的其实也是包括像谷歌啊提供的一些一些云服务的这种东西一旦他背后后面做一些商业化的东西基本上是没有人能够再去做这件事情的对这个人其实也是一个这个技术的这种垄断性我觉得也是蛮蛮有可能的一个方式甚至产生一些军备禁灾呀这个这个其实我我觉得才是才是我我真正比较担心的就是很多人都会比较担心的一个点

431
01:05:57,980 --> 01:06:05,820
其实这种东西他自己其其实东西有点像什么有点像核武器核武器如果很多人都有那么是维护世界和平

432
01:06:05,820 --> 01:06:21,620
如果垄断在少数几个人手上那就是毁灭人类的武器四四四王老师刚才说的这个写论文的助手啊我倒觉得应该是有高度的可行性的比刚才老庄说的那个要容易多了

433
01:06:21,620 --> 01:06:26,620
我跟你讲一个类似的应用案例啊就是这个会计审计

434
01:06:27,020 --> 01:06:37,540
啊就现在这个四大就是或四大或者五大反正那几个最大的这个快会计师事务所他们最长的工作就是做审计嘛那做审计怎么做呢

435
01:06:37,540 --> 01:06:44,460
他一般来讲是搜集标准化的一些原始数据然后做出一份叫做审计报告的底稿

436
01:06:45,460 --> 01:06:51,540
嗯这个底稿实际上就是把这些数据采集在来之后按照标准规范整理成一套文档

437
01:06:52,540 --> 01:07:03,260
然后在这个底稿基础之上啊再去做这个审计报告那审计报告可是王王就是发现问题了啊首先是概括和提出一些你的这个常规性判断

438
01:07:03,260 --> 01:07:11,460
比如你的健康度啊你的这个财务的合规程度等等然后就是一些问题发现就是你可能有哪些问题这些问题跟当地政策怎么有关系

439
01:07:11,460 --> 01:07:22,380
就是这么一个它实际上是一个很标准的嗯从有线的数据然后经历有线虽然很繁杂但仍然是有线的规则然后最后产出来的东西

440
01:07:22,380 --> 01:07:51,860
那我我知道的是大概在一一一六一七年一五一六年前后几乎四大里面所有的这个几个主要的这个这个事务所甚至也包括国内的一些没有那么有名气但是比较大的窥事务所都在投入去做这个呃人工智能的这方面的东西做什么呢就是自动的出那个底稿嗯理解后面一步后面一步它比较难做的原因在于各全世界各国

441
01:07:52,380 --> 01:08:00,460
对于会计准则里面它都是有一些所谓的叫做专业判断的部分所谓专业判断就是要由人来做判断的部分

442
01:08:01,380 --> 01:08:14,980
那这个呢就得呃专门的注册会计师或者是这个审计师来做了判断这些内容其实我是外行哈但是我也其实有一个不负责任的猜想我认为这部分其实哎也能做

443
01:08:14,980 --> 01:08:19,660
但为什么大家都不做呢那是要维护这些专业的会计师审计师的饭碗嘛

444
01:08:21,260 --> 01:08:30,460
所以这一块就先不去碰它了但是只要不是会计准则里面明确的这个专业判断的部分基本上都是可以继续生成的

445
01:08:32,460 --> 01:08:39,740
我专门问过一个当时到我们公司来做那个上市审计的一个一个很资深的一个一个人他就说质量非常好

446
01:08:40,580 --> 01:08:49,860
就是从不容易上来讲比他们就是平常用来做这个的那些安内斯就是那些分析师们要更快而且更就不会出错

447
01:08:51,460 --> 01:09:00,580
所以我我反过来讲我就觉得就是你说那个如果限定好一系列的范围和规则的话我觉得应该是完全有可能做得出来的

448
01:09:02,580 --> 01:09:09,580
对对对而且那个东西我觉得就基本上人处无害了就怎么做的问题不大了就就反正肯定是对人类好的

449
01:09:09,900 --> 01:09:18,060
不像这个最新的这些什么GPT啊这样的一些进展我觉得真的是有可能就应用不当的话是个挺恐怖的东西是是是

450
01:09:18,940 --> 01:09:30,180
OK呃那关于这个人工智能的话题啊我们也不是第一次聊了但是今天花了比较多的时间专门聊了一下从这个呃难不打的这个这个案例啊讲出来的一些东西

451
01:09:31,020 --> 01:09:38,100
嗯那那有一些事儿啊就顺便我们作为今天节目的结尾最后我们再聊一个小话题啊

452
01:09:38,540 --> 01:09:45,220
就是有些事儿我们在担心ai以假乱真所做出来东西给大家造成误解或者是造成危害

453
01:09:45,820 --> 01:09:51,780
嗯可能还远了一点儿啊我们眼下就有一个非常有趣的案例是人干的啊

454
01:09:52,300 --> 01:09:59,340
也是以假乱真啊但是这是人干的非常的有创意我我我很好奇不知道什么时候ai能干出这样的事来

455
01:09:59,740 --> 01:10:06,540
这个什么事儿呢就是最近维基皮特上的一个啊中文维基皮特就是维基百科上的一个

456
01:10:07,100 --> 01:10:16,300
一个一个一个黑乌龙事件啊什么事儿呢就是有一个中国的一个用户啊这个维基百科的用户

457
01:10:16,820 --> 01:10:24,380
他花了好长的时间在维基百科上编辑了大概有四五千个题这个条目

458
01:10:25,220 --> 01:10:30,260
累计的文字量大概有上百万的字上百万字的这个这个文字量

459
01:10:30,700 --> 01:10:39,140
在上面写了大量的关于古罗斯史就是俄罗斯那边的古代历史的这个条目啊编辑了几千个

460
01:10:39,140 --> 01:10:46,380
这里面他做了些什么事儿呢有很多他造出来的词条啊内容完全是虚构的

461
01:10:47,060 --> 01:10:53,900
但是他这些虚构的词条呢写的是非常的像模像样的啊就是你也看不出来他是乱写的

462
01:10:54,620 --> 01:11:01,620
更离谱的是他这些词条呢他全部都有非常标准的这种引用内容来源

463
01:11:02,020 --> 01:11:05,060
因为维基百科其实他没有特别多的审核

464
01:11:05,060 --> 01:11:12,020
对和错他只要求你说的所有东西都有都有出处都有可信的来源所以他有非常多的来源

465
01:11:12,500 --> 01:11:17,660
他来源怎么编呢编得很有意思比如说他造了一个呃完全不存在的一个银矿

466
01:11:18,500 --> 01:11:24,540
然后他说这个银矿的情况这样那样在哪里什么什么的个个都有出处出处也全都是真的

467
01:11:26,060 --> 01:11:31,020
只是他所写的这个出处比如某篇文章某本书里面压根就没提过他说这事儿

468
01:11:31,020 --> 01:11:39,180
啊他随便写某某书第二百页提到这件事情啊就他那个文章里他随便瞎写的而那本书一共只有五十页

469
01:11:40,580 --> 01:11:57,540
哦这就就就这样编出了一套完整的学术体系而且我听说的让我很惊讶的一件事情就是有不少的学校里面做研究或者是这样的人写论文的时候引用掉他这些东西然后全掉坑里去了

470
01:11:57,540 --> 01:11:58,300
掉坑里去了

471
01:11:59,580 --> 01:12:08,620
而这个事儿因为他已经写了改了四千多条的词条然后上百万的文字那肯定不是短期的是相当长时间的最近被发现了

472
01:12:09,020 --> 01:12:12,700
发现之后的话大部分词条就被删了然后他自己写了个道歉信

473
01:12:13,460 --> 01:12:21,460
按照他道歉信的说法这个他他他也不是故意造假啊他原来就是想把那个俄文的维基百科里面的一些内容翻译过来

474
01:12:21,740 --> 01:12:30,820
但他俄语又不灵他就找人帮忙然后自己半猜半弄啊然后猜怎么猜了猜就开始开始自己编了啊这这这么描述的

475
01:12:31,220 --> 01:12:36,260
然后他还指出就是说他很多东西就是从俄文的那里面搬过来的

476
01:12:36,740 --> 01:12:43,060
然后他发现很多东西他直接搬过来最后被证明是假的那就意味着原来俄文的那个也有问题

477
01:12:44,060 --> 01:12:49,700
他建议有有人去呃呃语好的可以去俄文的维基百科内去搞一搞

478
01:12:51,660 --> 01:12:58,140
对于也像那个蟑螂原理了就是说你当你发现一只蟑螂的时候可能背后有已经有上千只蟑螂在弟弟家跑了

479
01:12:59,260 --> 01:13:07,620
所以就是这么一个很著名的瓜这个事情对我的一个启发有两个点哈一个就是啊维体批点维基百科他

480
01:13:08,900 --> 01:13:11,420
他的内容我们到底怎么看待

481
01:13:12,940 --> 01:13:13,980
就他到底是一个

482
01:13:15,060 --> 01:13:20,860
就很多人现在在网上聊天甚至论战的时候会使用喜欢引用维基百科的内容

483
01:13:21,380 --> 01:13:28,220
但我其实很早我就觉得这个这个是有问题的呃就这个我们怎么看就是维基百科他到底是一个

484
01:13:28,860 --> 01:13:40,940
多么严肃和可信赖的一个信息源这是一个啊第二个就是多这只在普通人的角度哈第二个就是在学术圈在做研究的人里面他可以怎么去使用这些内容

485
01:13:42,340 --> 01:13:49,900
而实际上我我会觉得就是可能跟维基百科最早他被创创作创造出来的时候是不是已经有些变化

486
01:13:50,300 --> 01:13:59,860
这个我知道呢老庄应该也是很很多年的用户了这个王老师应该也也也非常多在使用这些东西那你们怎么看这个事情

487
01:14:01,700 --> 01:14:14,140
呃说实话首先首先我也非常多的用维基百科然后呢我通常会呃看情况吧如果是特别严肃的研究的我会去看他的多种语言

488
01:14:14,900 --> 01:14:19,860
然后去了解就是就是同一个词条的多种语言的版本看他们有什么差异

489
01:14:20,900 --> 01:14:29,020
但是我前段时间其实自己在研究那个新教伦理与资本主义精神嘛就那本书里面提到了很多很多的宗教人物

490
01:14:29,500 --> 01:14:39,700
然后就新教新教历史上的很多人物然后我就会去查他们的维基百科词条通常来说呢这个人比如他是法国的那么他的法文的词条会最多

491
01:14:40,220 --> 01:14:49,940
有长度啊严肃性啊都会最高如果他是一个英国人或者一个荷兰人或者一个德国人你最好去查他内媒语言的相应的字条效果会比较好

492
01:14:50,900 --> 01:14:57,660
这算是一个经验对另外呢还有一个就是说如果你真的你真的要要想去

493
01:14:58,900 --> 01:15:02,140
去追根究底的话那么他所有的引用的东西

494
01:15:03,100 --> 01:15:05,940
点过去再看的引用的内容里面到底有没有

495
01:15:06,940 --> 01:15:12,820
如如如果你要做严肃的学术研究的话不能够只是把维基百科的词条抄来就做

496
01:15:13,340 --> 01:15:21,100
这个只能这样讲但是其实很多时候我们默认的还是会比较相信维基百科

497
01:15:21,940 --> 01:15:24,380
今天听你听你说这个事情其实我是

498
01:15:25,180 --> 01:15:35,900
只能说调低评级吧也很无奈因为以前以前但凡我们觉得自己是一个比较认真严肃做互联网多年的人都会鄙视那些看百度百

499
01:15:35,940 --> 01:15:39,820
科的人是吧啊觉得我们用维基百科那不一样的

500
01:15:40,580 --> 01:15:51,260
但现在发现原来原来都都都不过如此而且其实另外还联想到一个啥事儿呢其实前段时间我们还聊到一个就是开源供应链投毒

501
01:15:52,340 --> 01:15:57,460
啊对就是一个家伙在开源代码里面对他他埋了恶意代码

502
01:15:58,620 --> 01:16:01,740
降低了所有人对开源软件的信任度

503
01:16:02,580 --> 01:16:13,100
他现在这个人做的这件事情其实哪怕他道歉恢复删除然后怎么样但事实上所有人对维基百科的整个信任度会降低

504
01:16:13,380 --> 01:16:15,380
这个是非常糟糕的一个一个事情

505
01:16:16,380 --> 01:16:22,740
嗯我先说到这其实我我其实其实我觉得这个事只是他的程度太夸张了

506
01:16:23,260 --> 01:16:27,500
但其实维基百科的这个问题啊由来已久

507
01:16:28,300 --> 01:16:33,420
嗯就是我我早就发现他里面已经有非常多的就是

508
01:16:34,220 --> 01:16:35,980
嗯第一非知识性的东西

509
01:16:36,860 --> 01:16:42,380
就是他他已经不是一种知识而是而很多东西是是观点性只是是立场性这东西了

510
01:16:42,740 --> 01:16:46,140
这是尤其在一些人物的这个页面上面会特别明显

511
01:16:47,540 --> 01:16:54,580
这是一个第二个呢就是他对于知识的表述啊因为他这种开放创作的这种理念

512
01:16:55,060 --> 01:17:02,260
他导致了一个就是翻倍四就是所谓的粉丝驱动而超过了专业驱动

513
01:17:03,780 --> 01:17:10,260
就是越是热心某件事情的人他的贡献越多然后他的影响力越大但他的专业度其实

514
01:17:11,180 --> 01:17:11,820
是不确定的

515
01:17:13,980 --> 01:17:23,420
所以所以他很多专业性的东西就有点像我们经常在网上看到的一句话就是我一开始都非常信任他直到他讲到了我专业的领域

516
01:17:24,300 --> 01:17:26,500
啊哈哈哈啊对对

517
01:17:27,700 --> 01:17:31,100
让你会开始发现哦这个这个比较成问题

518
01:17:32,660 --> 01:17:38,820
所以我现在个人的态度是这样的就是我把它看作是一个呃给入门的

519
01:17:39,820 --> 01:17:45,020
啊少年或者青年去看的百科全书就像你在

520
01:17:45,900 --> 01:17:50,260
书店里买到的一本百科啊然后就是入门去看一看就好了

521
01:17:50,660 --> 01:17:56,540
但如果你把它作为一个依据来论证一个很重要的事情那肯定是不够的绝对是不够的

522
01:17:57,220 --> 01:18:07,140
所以我其实当我听说嗯这个人的这个乌龙影响到了非常多的学校里面或者说研究机构的人做研究的论文的话我是非常的

523
01:18:07,540 --> 01:18:18,340
诧异的所以也也也特多我们专门跟跟王老师确认一下咱们现在学校里面去去发论文什么的可以把维基百科作为他的引用来源吗

524
01:18:20,260 --> 01:18:27,420
按理说维基百科里面内容没有被任何学术这个期刊收录过啊也就是说没有经过同行评审没有经过

525
01:18:27,780 --> 01:18:31,340
这种认可的东西怎么能够放在论文里作为依据引用呢

526
01:18:32,380 --> 01:18:40,780
对因为是这样的就是论文这件事情呢其实他的那个宽泛性和他的那个专业程度

527
01:18:41,180 --> 01:18:44,580
我个人觉得其实不像以前那么高了

528
01:18:45,060 --> 01:18:50,260
对就是那不光是因为现在大家培养的这些数字不是那么多嘛对吧

529
01:18:50,620 --> 01:18:59,340
就是甚至是一些那个不是这个学科或者是专业的人想去做这个领域的研究的这样的一些人其实也是越来越多了

530
01:18:59,660 --> 01:19:09,100
本身这个需求其实是实施在内里第二个就是学术论文里面其实他并没有规定说你的那个引用来源

531
01:19:09,660 --> 01:19:15,460
只能是一些严肃的学术期刊或者是不能够是一些什么东西他没有有这个规定

532
01:19:15,860 --> 01:19:21,420
所以说呢从一个专业的学术论文角度来说的话他的这个信息权其实是蛮多样性的

533
01:19:21,860 --> 01:19:32,700
他可以引用报纸可以引用杂志那当然也是可以引用伪基百科的那为什么这个观察的那虽然这工作就需要审论文的人去做了

534
01:19:33,700 --> 01:19:42,300
对那需要是假设你的这个论文的核心观点他的一个重要依据他的来源不够硬的话那相当就要在审这个论文的过程中才能够发现出来了

535
01:19:42,540 --> 01:19:48,020
对对这个这个就看你引用那个伪基百科里面内容去去支撑什么

536
01:19:48,380 --> 01:19:58,860
如果你是只是引用他去做一些通俗的一些定义和尝试的话一般不会有有太多的一些一些问题的但是如果就像那个李老师说的

537
01:19:59,380 --> 01:20:06,700
用来支撑一些核心观点特别是一些人文社科类的学科去支持一些观点的时候

538
01:20:07,140 --> 01:20:21,140
对其实会有很大的问题在自然科学里面总的来说要要好很多对因为像自然科学里面包括工程学里面他不会去用伪基百科里面去支持一些一些非常关键性的一些比如说数据呀公司推导呀

539
01:20:21,140 --> 01:20:32,620
对不会有的但是但是呢即便是这样其实从我自己的一些经历来说的话我们其实对伪基百科的信息的使用我个人觉得其实还是会越来越多的

540
01:20:33,180 --> 01:20:42,260
对不光是我们会在论文里面去引用写教材做课件很多时候都会去引用伪基百科里面比如说对云计算是什么定义的

541
01:20:42,780 --> 01:20:53,820
那基本上都已经成为一个标配了任何一个词一个专业术语我们都会去伪基百科上去去看一看对那那那那这个事件确实对我们来说也是一个一个挺大的挑战啊

542
01:20:55,260 --> 01:21:04,220
对我我对就其实我对他使用也是这样就是什么我觉得怎么样比较合适呢就是如果你想知道某个概念或者东西

543
01:21:04,740 --> 01:21:15,540
他被大众是如何理解和看待的那么你去引用伪基百科是完全没有问题的他代表了一种大众都接受的或者广为传播的说法

544
01:21:16,820 --> 01:21:17,860
这是完全没问题的

545
01:21:18,460 --> 01:21:24,180
对要这种使用方式其实就类似于你去书店里买一本字典或者是这个百科的书

546
01:21:24,660 --> 01:21:30,340
然后说哎这就是大众化的对某某事件某某动物某某人的理解

547
01:21:31,060 --> 01:21:40,980
就这样那这个没有问题但如果说你是要去用他来证明某一个关键性的事实或者是怎么样的话那我觉得这就肯定就不够了

548
01:21:41,740 --> 01:21:46,300
尤其重灾区啊是这个中文的伪基百科

549
01:21:47,420 --> 01:21:55,060
人文社科类哎呀这简直就是还有历史人物类的对这个懂的都懂啊这

550
01:21:56,060 --> 01:21:59,620
哈哈哈就是非常的可怕的一个一个一个一个状态

551
01:22:01,540 --> 01:22:07,940
其实是编辑战争嘛而且而且其实我可以多说两句因为我原来是在伪基百科还编辑过一些词条

552
01:22:08,700 --> 01:22:19,500
还当当初还创作过一些一些叫就说还真的可以稍微说多点就是说因为伪基百科刚刚创始没多久的时候那时候非常追求字条数量

553
01:22:20,140 --> 01:22:23,220
就说我们要要迅速的追上英文的字条数量

554
01:22:23,740 --> 01:22:31,020
而我当时在琢磨怎么才能够一口气创作更多的字条呢然后我就想了一个关键词叫小小吃

555
01:22:32,460 --> 01:22:42,540
啊像中国的小吃那么成千上万种那我先开一个字条叫小吃完了以后再把各地的小吃往下一练按几百个字条迅速就出来了

556
01:22:43,020 --> 01:22:50,300
这是这是当年我做的还是一桩比较得意的事情但是事实上呃在伪基百科上就后来就

557
01:22:51,140 --> 01:22:57,420
诞生了一个编辑战争就是大家为了某种意识形态啊什么的就就互相的

558
01:22:58,220 --> 01:23:01,980
就是你改我的我改你的还有很多词条被锁定这种事情都会有

559
01:23:02,500 --> 01:23:09,780
但是呢最不公平的一件事情就是我我也是对伪基百科有所怨念的就是现在几乎所有大陆的账号

560
01:23:10,300 --> 01:23:14,260
大陆的爱心弟子都不能够再登记自己的那个编辑账号

561
01:23:15,580 --> 01:23:24,460
所以对而且这就变成了我所知是我所知是是把有一些的早期的这些作者的账号啊

562
01:23:24,980 --> 01:23:28,500
写进黑名单了就跟你用什么ip登录都没关系了嗯

563
01:23:29,460 --> 01:23:32,100
这就是那一批的作者就就被干掉了对对

564
01:23:32,940 --> 01:23:36,900
接下来就是不公平的编辑战争我们现在的伪基百科上能够看到的词条

565
01:23:37,300 --> 01:23:41,580
尤其在意识形态方面的词条大陆的人是没办法上去编辑的

566
01:23:42,740 --> 01:23:46,460
还有很多关于人的也是嗯还有很多关于人的也是

567
01:23:47,060 --> 01:23:53,460
比如我我我最近发现的一个点虽然我早就已经看到了无数的案例了好像最近又发现了新的例子给大家分享的

568
01:23:53,940 --> 01:24:02,140
就前一段时间这个呃不是这个国外领去做这个美国的冬奥会的这个申办大使

569
01:24:02,980 --> 01:24:08,620
国内引起了一些讨论其实这个事也很正常因为这个跨国的去做这个形象大使

570
01:24:09,020 --> 01:24:13,900
比如当年我们申奥的时候那个谁啊有一个美籍华人啊叫张德培

571
01:24:14,420 --> 01:24:21,500
这个在我那个年纪还是非常非常出名的就是在九零年代世界上最优秀的几个男子网球运动员之一

572
01:24:22,020 --> 01:24:29,220
好像也是唯一的一个拿到大满贯的冠军的亚裔男子网球选手他就是

573
01:24:29,220 --> 01:24:38,260
是台湾人在那个北美的后裔啊他他他应该是ABC了他他不是在国内出生的

574
01:24:39,140 --> 01:24:47,740
他以前的比如说百维基百科的词条都是写作这个美美籍华人啊国籍中华民国或类似这样子啊

575
01:24:48,180 --> 01:24:53,100
但是我最近这次去查他的资料的时候因为上次正好提起来这个事儿

576
01:24:53,940 --> 01:24:59,700
我一看已经被改了啊现在的说法叫做嗯在美国长大的台湾人

577
01:25:01,380 --> 01:25:02,300
嗯就这样

578
01:25:05,820 --> 01:25:11,860
所以这一类的已经我觉得已经十几年下来已经就是产生了非常非常多的

579
01:25:13,180 --> 01:25:18,940
文化遗产啊人好不好咱不评价但这个反正至少不是一个很正常的现象

580
01:25:18,940 --> 01:25:28,380
嗯 OK嗯今天我们就聊了三个方面的话题啊这个差不多也有一个多分头了啊这个

581
01:25:29,420 --> 01:25:39,980
如果大家喜欢我们的节目啊也欢迎就是点赞然后帮我们去传播啊这个我们每周日在逼占首发然后

582
01:25:40,580 --> 01:25:46,380
第二天会发在其他的比如说嗯apple的这个扑卡斯达还有小宇宙啊这样的一些平台上

583
01:25:46,900 --> 01:25:58,020
大家可以搜索和订阅然后有的时候我们会在周中周三或周四去做一些番外片啊请一些外面的嘉宾我们那些朋友来聊一些独特的一些话题

584
01:26:00,300 --> 01:26:03,860
那两位还有什么补充吗今天关于今天的我们聊这几个事儿

585
01:26:06,420 --> 01:26:07,900
没有了没有了

586
01:26:08,940 --> 01:26:14,060
好那我们今天的节目就到这里啊谢谢大家拜拜拜拜

